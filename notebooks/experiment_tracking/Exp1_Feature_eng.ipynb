{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk textacy\n",
        "! pip install scikit-learn\n",
        "! pip install mlflow\n",
        "! pip install dagshub"
      ],
      "metadata": {
        "id": "erv5IAVyf4SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90259f28-c251-4385-9ec7-1d387f082381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.5.0)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.0.1)\n",
            "Requirement already satisfied: floret~=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.10.5)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.1.2)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.26.4)\n",
            "Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.17.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.5.2)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.7.5)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->textacy) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.5.0)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy~=3.0->textacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (4.12.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy~=3.0->textacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy~=3.0->textacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy~=3.0->textacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy~=3.0->textacy) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.19.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.19.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.0.3)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.14.0)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (0.39.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (4.25.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.19.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (0.49b2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.6.1)\n",
            "Requirement already satisfied: dagshub in /usr/local/lib/python3.10/dist-packages (0.3.47)\n",
            "Requirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.10/dist-packages (from dagshub) (6.0.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.4.4)\n",
            "Requirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from dagshub) (8.1.7)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (0.28.1)\n",
            "Requirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.10/dist-packages (from dagshub) (3.1.43)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (13.9.4)\n",
            "Requirement already satisfied: dacite~=1.6.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.6.0)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from dagshub) (9.0.0)\n",
            "Requirement already satisfied: gql[requests] in /usr/local/lib/python3.10/dist-packages (from dagshub) (3.5.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from dagshub) (0.6.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dagshub) (2.2.2)\n",
            "Requirement already satisfied: treelib>=1.6.4 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.7.0)\n",
            "Requirement already satisfied: pathvalidate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dagshub) (2.8.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.35.82)\n",
            "Requirement already satisfied: dagshub-annotation-converter>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from dagshub) (0.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (5.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from dagshub-annotation-converter>=0.1.0->dagshub) (4.12.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.11)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->dagshub) (2.18.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from treelib>=1.6.4->dagshub) (1.17.0)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.82 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (1.35.82)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->dagshub) (0.10.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->dagshub) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->dagshub) (0.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (3.2.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (1.18.3)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (2.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (2024.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.2.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.82->boto3->dagshub) (2.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.0->dagshub) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.0->dagshub) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textacy import preprocessing\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import mlflow\n",
        "import dagshub\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTP0-S70fJGk",
        "outputId": "58a6e09d-f569-4e09-bd08-ff7e6544b353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0voNIAkAe2Pr"
      },
      "outputs": [],
      "source": [
        "def pre_processing(df):\n",
        "  print(\"Shape of the data frame\", df.shape)\n",
        "  print(\"Duplicates\", df.duplicated().sum())\n",
        "  print(\"Null Values:\" ,df.isnull().sum())\n",
        "\n",
        "  print(\"Dropping the duplicate records.....\")\n",
        "  df.drop_duplicates(inplace=True)\n",
        "\n",
        "  print(\"Dropping the null values\")\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  print(\"Changing data to lower case\")\n",
        "  df['clean_comment'] = df['clean_comment'].str.lower()\n",
        "\n",
        "  df['length_clean_comment'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "\n",
        "  print(\"Strip off the white spaces..\")\n",
        "  df['clean_comment'] = df['clean_comment'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "  df['length_clean_comment_nowhite_space'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "  print(\"Number of rows have white spaces:\" , df[df['length_clean_comment']!= df['length_clean_comment_nowhite_space']].shape[0])\n",
        "\n",
        "  print(\"Removing Html tags....\")\n",
        "  df['clean_comment'] = df['clean_comment'].apply(preprocessing.remove.html_tags)\n",
        "  df['length_nowhite_space_htmltag'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "  print(\"Number of rows have Html tags:\" , df[df['length_clean_comment_nowhite_space']!= df['length_nowhite_space_htmltag']].shape[0])\n",
        "\n",
        "  print(\"Removing Punctuation....\")\n",
        "  df['clean_comment'] = df['clean_comment'].apply(preprocessing.remove.punctuation)\n",
        "  df['length_htmltag_punctuation'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "  print(\"Number of rows have punctuation:\" , df[df['length_nowhite_space_htmltag']!= df['length_htmltag_punctuation']].shape[0])\n",
        "\n",
        "  print(\"Removing brackets....\")\n",
        "  df['clean_comment'] = df['clean_comment'].apply(preprocessing.remove.punctuation)\n",
        "  df['length_punctuation_brackets'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "  print(\"Number of rows have brackets:\" , df[df['length_htmltag_punctuation']!= df['length_punctuation_brackets']].shape[0])\n",
        "\n",
        "  # Apply the function to the 'clean_comment' column in a single line\n",
        "  df['clean_comment'] = df['clean_comment'].apply(lambda x: preprocessing.replace.emojis(x, \"\"))\n",
        "  df['length_brackets_emojis'] = df['clean_comment'].apply(lambda x: len(str(x)))\n",
        "  print(\"Number of rows have emojis:\" , df[df['length_punctuation_brackets']!= df['length_brackets_emojis']].shape[0])\n",
        "\n",
        "\n",
        "  # Regular expression to match emojis\n",
        "  emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "                            \"\\U0001F300-\\U0001F5FF\"  # Symbols and Pictographs\n",
        "                            \"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
        "                            \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
        "                            \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "                            \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "                            \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                            \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "                            \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                            \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                            \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
        "                            \"]\", flags=re.UNICODE)\n",
        "\n",
        "  # Filter out rows where 'clean_comment' contains emojis\n",
        "  print(\"Number of non meaning  rows:\", df[df['clean_comment'].apply(lambda x: bool(emoji_pattern.search(x)))].shape)\n",
        "  df = df[~df['clean_comment'].apply(lambda x: bool(emoji_pattern.search(x)))]\n",
        "\n",
        "\n",
        "  # List of words to keep even if their length is less than 4\n",
        "  keep_words = ['lol', 'wow', 'wtf', 'fun', 'sad', 'old']\n",
        "\n",
        "  # Filter out rows with clean_comment length < 4 unless they contain one of the keep_words\n",
        "  df = df[(df['length_clean_comment'] >= 4) | df['clean_comment'].isin(keep_words)]\n",
        "\n",
        "  return df[['clean_comment', 'category', 'length_clean_comment']]\n",
        "\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_comment1(comment):\n",
        "    # Convert to lowercase\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Remove trailing and leading whitespaces\n",
        "    comment = comment.strip()\n",
        "\n",
        "    # Remove newline characters\n",
        "    comment = re.sub(r'\\n', ' ', comment)\n",
        "\n",
        "    # Remove non-alphanumeric characters, except punctuation\n",
        "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
        "\n",
        "    return comment\n",
        "\n",
        "def preprocess_comment2(comment):\n",
        "\n",
        "      # Remove stopwords but retain important ones for sentiment analysis\n",
        "    stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
        "    comment = ' '.join([word for word in comment.split() if word not in stop_words])\n",
        "\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
        "    return comment\n",
        "\n",
        "def preprocess_unigram(df):\n",
        "    df = pre_processing(df)\n",
        "    df['clean_comment'] = df['clean_comment'].apply(preprocess_comment1)\n",
        "    df['clean_comment'] = df['clean_comment'].apply(preprocess_comment2)\n",
        "    return df\n",
        "\n",
        "def preprocess_multigram(df):\n",
        "    df = pre_processing(df)\n",
        "    df['clean_comment'] = df['clean_comment'].apply(preprocess_comment1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.3, random_state=42, stratify=df['category'])\n",
        "\n",
        "\n",
        "\n",
        "# Concatenate DataFrames side by side\n",
        "result = pd.concat([X_train, y_train], axis=1)\n",
        "result1 = preprocess_unigram(result)\n",
        "\n",
        "# Data for training\n",
        "X_train_uni = result1['clean_comment']\n",
        "y_train_uni = result1['category']\n",
        "\n",
        "result_test = pd.concat([X_test, y_test], axis=1)\n",
        "result_test1 = preprocess_unigram(result_test)\n",
        "\n",
        "# Data for testing\n",
        "X_test_uni = result_test1['clean_comment']\n",
        "y_test_uni = result_test1['category']\n",
        "\n",
        "\n",
        "result = pd.concat([X_train, y_train], axis=1)\n",
        "result1 = preprocess_multigram(result)\n",
        "\n",
        "# Data for training\n",
        "X_train_multi = result1['clean_comment']\n",
        "y_train_multi = result1['category']\n",
        "\n",
        "result_test = pd.concat([X_test, y_test], axis=1)\n",
        "result_test1 = preprocess_multigram(result_test)\n",
        "\n",
        "# Data for testing\n",
        "X_test_multi = result_test1['clean_comment']\n",
        "y_test_multi = result_test1['category']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGF4PRVcWWAW",
        "outputId": "0e0e405d-4f36-45f1-f2b0-1f3a4b2b5e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the data frame (26074, 2)\n",
            "Duplicates 277\n",
            "Null Values: clean_comment    75\n",
            "category          0\n",
            "dtype: int64\n",
            "Dropping the duplicate records.....\n",
            "Dropping the null values\n",
            "Changing data to lower case\n",
            "Strip off the white spaces..\n",
            "Number of rows have white spaces: 22730\n",
            "Removing Html tags....\n",
            "Number of rows have Html tags: 0\n",
            "Removing Punctuation....\n",
            "Number of rows have punctuation: 0\n",
            "Removing brackets....\n",
            "Number of rows have brackets: 0\n",
            "Number of rows have emojis: 39\n",
            "Number of non meaning  rows: (109, 8)\n",
            "Shape of the data frame (11175, 2)\n",
            "Duplicates 88\n",
            "Null Values: clean_comment    25\n",
            "category          0\n",
            "dtype: int64\n",
            "Dropping the duplicate records.....\n",
            "Dropping the null values\n",
            "Changing data to lower case\n",
            "Strip off the white spaces..\n",
            "Number of rows have white spaces: 9755\n",
            "Removing Html tags....\n",
            "Number of rows have Html tags: 0\n",
            "Removing Punctuation....\n",
            "Number of rows have punctuation: 0\n",
            "Removing brackets....\n",
            "Number of rows have brackets: 0\n",
            "Number of rows have emojis: 16\n",
            "Number of non meaning  rows: (39, 8)\n",
            "Shape of the data frame (26074, 2)\n",
            "Duplicates 277\n",
            "Null Values: clean_comment    75\n",
            "category          0\n",
            "dtype: int64\n",
            "Dropping the duplicate records.....\n",
            "Dropping the null values\n",
            "Changing data to lower case\n",
            "Strip off the white spaces..\n",
            "Number of rows have white spaces: 22730\n",
            "Removing Html tags....\n",
            "Number of rows have Html tags: 0\n",
            "Removing Punctuation....\n",
            "Number of rows have punctuation: 0\n",
            "Removing brackets....\n",
            "Number of rows have brackets: 0\n",
            "Number of rows have emojis: 39\n",
            "Number of non meaning  rows: (109, 8)\n",
            "Shape of the data frame (11175, 2)\n",
            "Duplicates 88\n",
            "Null Values: clean_comment    25\n",
            "category          0\n",
            "dtype: int64\n",
            "Dropping the duplicate records.....\n",
            "Dropping the null values\n",
            "Changing data to lower case\n",
            "Strip off the white spaces..\n",
            "Number of rows have white spaces: 9755\n",
            "Removing Html tags....\n",
            "Number of rows have Html tags: 0\n",
            "Removing Punctuation....\n",
            "Number of rows have punctuation: 0\n",
            "Removing brackets....\n",
            "Number of rows have brackets: 0\n",
            "Number of rows have emojis: 16\n",
            "Number of non meaning  rows: (39, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_uni.iloc[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "qDUIvo47ZNTO",
        "outputId": "595b843c-5287-49e4-8c9a-cef27c3de862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34723                                                     \n",
              "25401     hey maybe poor lobbyist super pac would get want\n",
              "35461    actual fuck really say sarcasm mean lawyer not...\n",
              "28317    chill fuck going attack karachi city bullshit ...\n",
              "13636              keep hearing great thing india good guy\n",
              "                               ...                        \n",
              "17682    justice department need shut former president ...\n",
              "28314    enter pak airspace today saw video circulated ...\n",
              "8918                     going retire get married live man\n",
              "22000    ouch bite south aiadmk controlled bjp anger ch...\n",
              "31780    deccan herald always unique take event think o...\n",
              "Name: clean_comment, Length: 25661, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34723</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25401</th>\n",
              "      <td>hey maybe poor lobbyist super pac would get want</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35461</th>\n",
              "      <td>actual fuck really say sarcasm mean lawyer not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28317</th>\n",
              "      <td>chill fuck going attack karachi city bullshit ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13636</th>\n",
              "      <td>keep hearing great thing india good guy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17682</th>\n",
              "      <td>justice department need shut former president ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28314</th>\n",
              "      <td>enter pak airspace today saw video circulated ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8918</th>\n",
              "      <td>going retire get married live man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22000</th>\n",
              "      <td>ouch bite south aiadmk controlled bjp anger ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31780</th>\n",
              "      <td>deccan herald always unique take event think o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25661 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dagshub.init(repo_owner='MitVinay', repo_name='youtube_chrome', mlflow=True)\n",
        "mlflow.set_experiment(\"Exp1-Feature_eng\")\n",
        "\n",
        "# Start parent run\n",
        "with mlflow.start_run() as parent_run:\n",
        "# Define the n-grams range\n",
        "  n_grams = [(1, 1), (1, 2), (1, 3)]\n",
        "\n",
        "  # Automate the process for both CountVectorizer and TfidfVectorizer\n",
        "  vectorizers = {\n",
        "      \"CountVectorizer\": CountVectorizer,\n",
        "      \"TfidfVectorizer\": TfidfVectorizer\n",
        "  }\n",
        "\n",
        "  for ngram in n_grams:\n",
        "      for vect_name, vect_class in vectorizers.items():\n",
        "          with mlflow.start_run(nested=True, run_name=f\"{ngram} using {vect_name}_new_version\") as child_run:\n",
        "            print(f\"Testing with n-gram range: {ngram} using {vect_name}\")\n",
        "\n",
        "            mlflow.set_tag(\"mlflow.runName\", f\"{vect_name}_{ngram}_RandomForest\")\n",
        "            mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "            mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "            # Initialize the vectorizer\n",
        "            vectorizer = vect_class(ngram_range=ngram, max_features=1000)\n",
        "\n",
        "            if ngram == (1, 1):\n",
        "\n",
        "              # Data for testing\n",
        "              X_test = X_test_uni\n",
        "              y_test = y_test_uni\n",
        "\n",
        "              # Data for training\n",
        "              X_train = X_train_uni\n",
        "              y_train = y_train_uni\n",
        "              print(\"Splitting done\")\n",
        "            else:\n",
        "              X_test = X_test_multi\n",
        "              y_test = y_test_multi\n",
        "\n",
        "              X_train = X_train_multi\n",
        "              y_train = y_train_multi\n",
        "\n",
        "            X_train_vect = vectorizer.fit_transform(X_train)\n",
        "            X_test_vect = vectorizer.transform(X_test)\n",
        "            print(\"Vectorizer done\")\n",
        "            # Train the RandomForestClassifier\n",
        "            rf = RandomForestClassifier(random_state=42)\n",
        "            rf.fit(X_train_vect, y_train)\n",
        "            print(\"Random forest done\")\n",
        "\n",
        "            # Predict and evaluate\n",
        "            y_pred = rf.predict(X_test_vect)\n",
        "            metrics = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "            for label, metrics_dict in metrics.items():\n",
        "              if label != 'accuracy':  # 'accuracy' is logged separately as a single value\n",
        "                  for metric, value in metrics_dict.items():\n",
        "                      mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "              else:\n",
        "                  # Log the accuracy score separately\n",
        "                  mlflow.log_metric(\"accuracy\", metrics_dict)\n",
        "\n",
        "\n",
        "            mlflow.log_param(\"max_features\", 1000)\n",
        "            mlflow.log_param(\"ngram_range\", ngram)\n",
        "            mlflow.log_param(\"vectorizer\", vect_name)\n",
        "            mlflow.sklearn.log_model(rf, f\"random_forest_model_{vect_name}_{ngram}\")\n",
        "\n",
        "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "            plt.xlabel(\"Predicted\")\n",
        "            plt.ylabel(\"Actual\")\n",
        "            plt.title(f\"Confusion Matrix: {vect_name}, {ngram}\")\n",
        "            plt.savefig(\"confusion_matrix.png\")\n",
        "            mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "            plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "O1ho5lM_UPwo",
        "outputId": "45fd9e04-7dd2-4a9c-c4c7-be6db314b667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"MitVinay/youtube_chrome\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MitVinay/youtube_chrome\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository MitVinay/youtube_chrome initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MitVinay/youtube_chrome initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with n-gram range: (1, 1) using CountVectorizer\n",
            "Splitting done\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 11:52:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run CountVectorizer_(1, 1)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/cce5bb0060dc4d61b0d8a8c23b7c1aca\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "Testing with n-gram range: (1, 1) using TfidfVectorizer\n",
            "Splitting done\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 11:54:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run TfidfVectorizer_(1, 1)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/942e1beda9a14f98aaeff40e41d96126\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "Testing with n-gram range: (1, 2) using CountVectorizer\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 11:55:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run CountVectorizer_(1, 2)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/f6444f267eaf48efb02d530760ebc50a\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "Testing with n-gram range: (1, 2) using TfidfVectorizer\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 11:57:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run TfidfVectorizer_(1, 2)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/8712272c79324b83a5b02e7536a7b9ca\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "Testing with n-gram range: (1, 3) using CountVectorizer\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 11:58:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run CountVectorizer_(1, 3)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/84c34d93c7aa4e0483d4e9b5ca17950f\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "Testing with n-gram range: (1, 3) using TfidfVectorizer\n",
            "Vectorizer done\n",
            "Random forest done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2024/12/17 12:00:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸƒ View run TfidfVectorizer_(1, 3)_RandomForest at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/2503444fa158479792a621e6a4df113a\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n",
            "ðŸƒ View run unequaled-swan-97 at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2/runs/5dd56316eaea4cb5aa4922d78dbcb964\n",
            "ðŸ§ª View experiment at: https://dagshub.com/MitVinay/youtube_chrome.mlflow/#/experiments/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams = [(1, 1), (2, 2), (3, 3)]"
      ],
      "metadata": {
        "id": "d8eM04eFgOP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}